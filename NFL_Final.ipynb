{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e0aad6f-0fbc-4fdd-9be7-1275c1b48c81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T10:50:59.626493Z",
     "iopub.status.busy": "2022-03-22T10:50:59.626493Z",
     "iopub.status.idle": "2022-03-22T10:51:07.317075Z",
     "shell.execute_reply": "2022-03-22T10:51:07.316623Z",
     "shell.execute_reply.started": "2022-03-22T10:50:59.626493Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from string import punctuation\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow.keras \n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import backend as K\n",
    "import time\n",
    "data=pd.read_csv('train.csv',low_memory=False)\n",
    "data['PlayId']=data['PlayId'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f612d2c5-a6f6-4d89-9978-f4c474414468",
   "metadata": {},
   "source": [
    "## Function 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d58ab4-6d30-4b21-84d1-82bb839871ec",
   "metadata": {},
   "source": [
    "Takes a play from from the dataset in shape (22,52) and returns the top 5 predictions with the accompanying Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9330a9ff-a0c9-42e0-b39a-446094d920c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T09:18:52.718656Z",
     "iopub.status.busy": "2022-03-22T09:18:52.718266Z",
     "iopub.status.idle": "2022-03-22T09:18:52.758035Z",
     "shell.execute_reply": "2022-03-22T09:18:52.756997Z",
     "shell.execute_reply.started": "2022-03-22T09:18:52.718656Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def function_1(point):\n",
    "    np.random.seed(43)\n",
    "    start=time.time()\n",
    "    data=pd.read_csv('train.csv',low_memory=False)\n",
    "    end=time.time()\n",
    "    print('Time taken to read data:', round(end-start),'s')\n",
    "    \n",
    "    start=time.time()\n",
    "\n",
    "    orient=data.groupby('Position',as_index=False)['Orientation'].mean()\n",
    "    Dir=data.groupby('Position',as_index=False)['Dir'].mean()\n",
    "    OrientDict={}\n",
    "    DirDict={}\n",
    "    for i,j in orient.iterrows():\n",
    "        OrientDict[j['Position']]=j['Orientation']\n",
    "        DirDict[j['Position']]=j['Orientation']\n",
    "\n",
    "    data.Dir=data.Dir.fillna(data.Position.map(DirDict))\n",
    "    data.Orientation=data.Orientation.fillna(data.Position.map(OrientDict))\n",
    "\n",
    "    tempsperweek=data.groupby(['Season','Week'],as_index=False)['Temperature'].mean()\n",
    "    temp2017={}\n",
    "    temp2018={}\n",
    "    temp2019={}\n",
    "    for i,j in tempsperweek.iterrows():\n",
    "        if j['Season']==2017:\n",
    "            temp2017[j['Week']]=j['Temperature']\n",
    "        if j['Season']==2018:\n",
    "            temp2018[j['Week']]=j['Temperature']\n",
    "        if j['Season']==2019:\n",
    "            temp2019[j['Week']]=j['Temperature']\n",
    "\n",
    "    data.loc[(data.Season==2017) & (data.Temperature.isna()),'Temperature']=data.Temperature.fillna(data.Week.map(temp2017))\n",
    "    data.loc[(data.Season==2018) & (data.Temperature.isna()),'Temperature']=data.Temperature.fillna(data.Week.map(temp2018))\n",
    "    data.loc[(data.Season==2019) & (data.Temperature.isna()),'Temperature']=data.Temperature.fillna(data.Week.map(temp2019))\n",
    "\n",
    "    data.loc[data.FieldPosition.isna(),'FieldPosition']='UNKNOWN'\n",
    "    data.loc[data.OffenseFormation.isna(),'OffenseFormation']=data.OffenseFormation.value_counts().idxmax()\n",
    "\n",
    "    data.loc[data.DefendersInTheBox.isna(),'DefendersInTheBox']=data.DefendersInTheBox.median()\n",
    "    data.loc[data.Humidity.isna(),'Humidity']=data.Humidity.median()\n",
    "\n",
    "\n",
    "    #Code to clean StadiumType \n",
    "    #code inspired from https://www.kaggle.com/sanshengshi/lightgbm-clean-stadiumtype\n",
    "    def StadiumType(txt):\n",
    "        txt=str(txt)\n",
    "        txt=txt.lower()\n",
    "        txt=txt.strip()\n",
    "        if 'indoor' in txt or 'closed' in txt:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1   #outdoor or open or unspecified is being treated an as open field \n",
    "    data[\"StadiumType\"]=data[\"StadiumType\"].apply(StadiumType)\n",
    "\n",
    "    def Gameweather(txt):\n",
    "        txt=str(txt)\n",
    "        txt=txt.lower()\n",
    "        txt=txt.strip()\n",
    "        if 'clear' in txt or 'sun' in txt or 'controlled' in txt or 'indoor' in txt:\n",
    "            return 0\n",
    "        if 'rain' in txt:\n",
    "            return 1\n",
    "        if 'cloud' in txt or 'overcast' in txt:\n",
    "            return 0.5 \n",
    "        if 'snow' in txt or 'overcast' in txt:\n",
    "            return -0.5\n",
    "        return 0                                   # Values given to differentiate between clear and rainy \n",
    "    data[\"GameWeather\"]=data[\"GameWeather\"].apply(Gameweather)\n",
    "\n",
    "    def Windspeed(txt):\n",
    "        if pd.isna(txt):\n",
    "            return 7.0                   # Median Value   \n",
    "        if '-' in txt:\n",
    "            a,b=txt.split('-')\n",
    "            return (float(a)+float(b))/2\n",
    "        elif txt.isalnum():\n",
    "            if re.match('(\\d+)',str(txt)):\n",
    "                return float(re.match('(\\d+)',str(txt))[0])\n",
    "            else:\n",
    "                return 7.0\n",
    "        else:\n",
    "            return 0\n",
    "    data[\"WindSpeed\"]=data[\"WindSpeed\"].astype(str)\n",
    "    data[\"WindSpeed\"]=data[\"WindSpeed\"].apply(Windspeed)\n",
    "\n",
    "\n",
    "    # code based from https://www.kaggle.com/bgmello/neural-networks-feature-engineering-for-the-win\n",
    "    def WindDirection(txt):\n",
    "\n",
    "        #Cleaning the values\n",
    "        if pd.isna(txt):\n",
    "            return -1\n",
    "        txt = txt.lower()\n",
    "        txt = ''.join([c for c in txt if c not in punctuation])\n",
    "        txt = txt.replace('from', '')\n",
    "        txt = txt.replace(' ', '')\n",
    "        txt = txt.replace('north', 'n')\n",
    "        txt = txt.replace('south', 's')\n",
    "        txt = txt.replace('west', 'w')\n",
    "        txt = txt.replace('east', 'e')\n",
    "\n",
    "        #assigning the values\n",
    "\n",
    "        deg=360\n",
    "        if txt=='n':\n",
    "            return 0\n",
    "        if txt=='nne' or txt=='nen':\n",
    "            return 1/16*deg\n",
    "        if txt=='ne':\n",
    "            return 2/16*deg\n",
    "        if txt=='ene' or txt=='nee':\n",
    "            return 3/16*deg\n",
    "        if txt=='e':\n",
    "            return 4/16*deg\n",
    "        if txt=='ese' or txt=='see':\n",
    "            return 5/16*deg\n",
    "        if txt=='se':\n",
    "            return 6/16*deg\n",
    "        if txt=='ses' or txt=='sse':\n",
    "            return 7/16*deg\n",
    "        if txt=='s':\n",
    "            return 8/16*deg\n",
    "        if txt=='ssw' or txt=='sws':\n",
    "            return 9/16*deg\n",
    "        if txt=='sw':\n",
    "            return 10/16*deg\n",
    "        if txt=='sww' or txt=='wsw':\n",
    "            return 11/16*deg\n",
    "        if txt=='w':\n",
    "            return 12/16*deg\n",
    "        if txt=='wnw' or txt=='nww':\n",
    "            return 13/16*deg\n",
    "        if txt=='nw':\n",
    "            return 14/16*deg\n",
    "        if txt=='nwn' or txt=='nnw':\n",
    "            return 15/16*deg\n",
    "        return -1\n",
    "                                          # Values given to differentiate between clear and rainy \n",
    "    data[\"WindDirection\"]=data[\"WindDirection\"].apply(WindDirection)\n",
    "    \n",
    "    TeamMap={'ARI':'ARZ','BAL':'BLT','CLE':'CLV','HOU':'HST'}\n",
    "\n",
    "    for k,v in TeamMap.items():\n",
    "        data.loc[data['VisitorTeamAbbr']==k,'VisitorTeamAbbr']=v\n",
    "        data.loc[data['HomeTeamAbbr']==k,'HomeTeamAbbr']=v\n",
    "    data['PlayId']=data['PlayId'].astype(str)\n",
    "    data['PlayerHeight']=data['PlayerHeight'].astype(str)\n",
    "    data['PlayerHeight']=data['PlayerHeight'].str.split('-').apply(lambda x: int(x[0])*0.3048+ int(x[1])*0.0254)\n",
    "    data['PlayerWeight']=data['PlayerWeight']*0.453592\n",
    "    \n",
    "    \n",
    "    \n",
    "    #first 3 Downs have similar distribution\n",
    "    data['Down']=data.Down.apply(lambda x: 1 if x<3 else 0)\n",
    "    #Standardise Play Direction and dependent features\n",
    "    data['Left']=data.PlayDirection=='left'\n",
    "    \n",
    "    data['X_std']=data.X\n",
    "    data.loc[data.Left,'X_std']=120-data.loc[data.Left,'X']\n",
    "    data['Y_std']=data.Y\n",
    "    data.loc[data.Left,'Y_std']=160/3-data.loc[data.Left,'Y']\n",
    "    \n",
    "    #Rusher varibale to indicate the rushing player\n",
    "    data['Rusher']=data.NflId==data.NflIdRusher\n",
    "    \n",
    "    data['Offense'] = \"home\"\n",
    "    # If attacking team is not home team, it is treated as away team\n",
    "    data.loc[data.PossessionTeam != data.HomeTeamAbbr, 'Offense'] = \"away\"\n",
    "    # If Field position and possession team are same then the Yardline values stay same. Otherwise it is in the opposite direction\n",
    "    data['YardLine_std'] = 100 - data.YardLine\n",
    "    data.loc[data.FieldPosition == data.PossessionTeam,'YardLine_std'] = data.loc[data.FieldPosition == data.PossessionTeam,'YardLine']\n",
    "    \n",
    "    # Degrees to Radians subtracting by 90 since 0 degrees is upwards in raw data and it doesn't make intuitve sense, \n",
    "    # towards right is gven as 0 and towards left as 180 degrees or pi radians\n",
    "    data['Dir_std']=np.mod(90-data.Dir,360)*np.pi/180\n",
    "    #Flipping direction of all Left direction by pi radians (180 degrees)\n",
    "    data.loc[data['Left'],'Dir_std']=np.mod(np.pi-data.loc[data['Left'],'Dir_std'],2*np.pi)\n",
    "    \n",
    "    data.drop(['X','Y','Dir','YardLine'],axis=1,inplace=True)\n",
    "    \n",
    "    #Data Engineering\n",
    "    \n",
    "    #Values taken just from looking at the distrubition of data after comparing 2017 with other Seasons(2018/19)\n",
    "    #Number of samples also taken after looking at the corresponding values in 2018/2019 data respectively \n",
    "    index=data.loc[(data.Season==2017) & (data.Dis==0.0)].sample(2200).index                                          \n",
    "    data.loc[index.values,'Dis']=np.round(np.random.uniform(0.1,0.4,2200),decimals=2)      \n",
    "    index=data.loc[(data.Season==2017) & (data.Dis==0.01)].sample(4000).index\n",
    "    data.loc[index.values,'Dis']=np.round(np.random.uniform(0.1,0.4,4000),decimals=2)\n",
    "    \n",
    "    #201 orientation off byy a phase of 90 degrees\n",
    "    data.loc[data.Season==2017,'Orientation']=np.mod(90+data.loc[data.Season==2017,'Orientation'],360)\n",
    "    \n",
    "    \n",
    "    end=time.time()\n",
    "    print('Time to preprocess full data',round(end-start),'s')\n",
    "    \n",
    "    \n",
    "    start=time.time()\n",
    "    \n",
    "    data=data.loc[data.PlayId==point.PlayId.unique()[0]]\n",
    "    \n",
    "    \n",
    "    #creating a Play only based Dataframe\n",
    "    df_rush=data.loc[data.Rusher]\n",
    "    \n",
    "    \n",
    "    #Feature engineering for features relative to the Rusher\n",
    "    \n",
    "    #https://www.kaggle.com/jccampos/nfl-2020-winner-solution-the-zoo\n",
    "    # Getting Speed component along vertical and Horizontal Axis\n",
    "    data['S_x'] = data['S']*data['Dir_std'].apply(math.cos)\n",
    "    data['S_y'] = data['S']*data['Dir_std'].apply(math.sin)\n",
    "\n",
    "    #Momentum=mass*velocity along vertical and Horizontal Axis\n",
    "    data['M_x']=data.PlayerWeight*data['S_x']\n",
    "    data['M_y']=data.PlayerWeight*data['S_y']\n",
    "\n",
    "\n",
    "    rush=data[data.Rusher]\n",
    "    rush.set_index('PlayId',inplace=True,drop=True)\n",
    "    #Converting to Dictionary the values of Rusher\n",
    "    mapp=rush[['X_std','Y_std','S_x','S_y','M_x','M_y']].to_dict(orient='index')\n",
    "\n",
    "    #Creating columns which contain the rusher values to all PlayIds\n",
    "    rush_x=data['PlayId'].apply(lambda x:mapp[x]['X_std'])\n",
    "    rush_y=data['PlayId'].apply(lambda y:mapp[y]['Y_std'])\n",
    "    rush_Sx=data['PlayId'].apply(lambda x:mapp[x]['S_x'])\n",
    "    rush_Sy=data['PlayId'].apply(lambda y:mapp[y]['S_y'])\n",
    "    rush_Mx=data['PlayId'].apply(lambda x:mapp[x]['M_x'])\n",
    "    rush_My=data['PlayId'].apply(lambda y:mapp[y]['M_y'])\n",
    "    \n",
    "    #Euclidean Distance between Rusher and other players\n",
    "    data['gap']=((rush_x-data['X_std'])**2+(rush_y-data['Y_std'])**2)**0.5\n",
    "    data['inverse_gap']=data['gap'].apply(lambda x: 1/x if x!=0 else -1)\n",
    "    #Relative Speeds between Rusher and other players\n",
    "    data['RelS_x']=rush_Sx-data['S_x']\n",
    "    data['RelS_y']=rush_Sy-data['S_y']\n",
    "    # Relative Momentum between Rusher and other players\n",
    "    data['RelM_x']=rush_Mx-data['M_x']\n",
    "    data['RelM_y']=rush_My-data['M_y']  \n",
    "\n",
    "\n",
    "    #Code to collapse all 22 players involved per PlayId into a single row arranged from highest to lowest.\n",
    "    playids=data.PlayId.unique()\n",
    "    A=data['gap'].values\n",
    "    B=data['RelS_x'].values\n",
    "    C=data['RelS_y'].values\n",
    "    D=data['inverse_gap'].values\n",
    "    E=data['RelM_x'].values\n",
    "    F=data['RelM_y'].values\n",
    "    n=len(playids)\n",
    "    val_dict={}\n",
    "    for i in range(0,n):\n",
    "        val_dict[playids[i]]=sorted(A[i*22:i*22+22],reverse=True)+sorted(D[i*22:i*22+22])+\\\n",
    "                            sorted(B[i*22:i*22+22],reverse=True)+sorted(C[i*22:i*22+22],reverse=True)+\\\n",
    "                            sorted(E[i*22:i*22+22],reverse=True)+sorted(F[i*22:i*22+22],reverse=True)\n",
    "    val_cols=['P_{0}'.format(i+1) for i in range(0,22)]+['P_Invd_{0}'.format(i+1) for i in range(0,22)]+\\\n",
    "                ['Sx_{0}'.format(i+1) for i in range(0,22)]+['Sy_{0}'.format(i+1) for i in range(0,22)]+\\\n",
    "            ['Mx_{0}'.format(i+1) for i in range(0,22)]+['My_{0}'.format(i+1) for i in range(0,22)]\n",
    "\n",
    "    rel_data=pd.DataFrame(data=val_dict.values(),columns=val_cols,index=list(val_dict.keys()))\n",
    "    rel_data.index.rename('PlayId',inplace=True)\n",
    "    \n",
    "    #Combining Game state and Relative player dataframes    \n",
    "    final_df=pd.merge(df_rush,rel_data,on='PlayId')\n",
    "    Y=final_df.Yards.values\n",
    "    \n",
    "    #Dropping redundant or features which don't seem useful \n",
    "    final_df.drop([ 'GameId','S','NflId','Team',\n",
    "           'DisplayName', 'JerseyNumber', 'Season', 'GameClock',\n",
    "           'PossessionTeam', 'FieldPosition',\n",
    "           'HomeScoreBeforePlay', 'VisitorScoreBeforePlay', 'NflIdRusher',\n",
    "           'OffenseFormation', 'OffensePersonnel', 'DefendersInTheBox',\n",
    "           'DefensePersonnel', 'PlayDirection', 'TimeHandoff', 'TimeSnap',\n",
    "           'PlayerHeight', 'PlayerWeight', 'PlayerBirthDate', 'PlayerCollegeName',\n",
    "           'Position', 'HomeTeamAbbr', 'VisitorTeamAbbr', 'Stadium',\n",
    "           'Location', 'StadiumType', 'Turf','Left', 'X_std', 'Y_std',\n",
    "           'Rusher', 'Offense', 'Dir_std','Yards'],inplace=True,axis=1)\n",
    "    \n",
    "    final_df.set_index('PlayId',inplace=True)\n",
    "    Y=np.array(Y).reshape(-1,1)\n",
    "    targets = Y\n",
    "    test=np.zeros((Y.shape[0],199))\n",
    "    \n",
    "    #converting into cdf format\n",
    "    for idx, t in enumerate(list(Y)):\n",
    "        test[idx][99 + t[0]] = 1\n",
    "    \n",
    "    #Loading Model and CRPS function\n",
    "    def crps_nn(y_true,y_pred):\n",
    "        loss = K.mean(K.sum((K.cumsum(y_pred, axis = 1) - K.cumsum(y_true, axis=1))**2, axis=1))/199\n",
    "        return loss\n",
    "\n",
    "    model=load_model('nfl_pred.hdf5',custom_objects={'crps_nn':crps_nn})   \n",
    "    \n",
    "\n",
    "    preds=model.predict(final_df)\n",
    "    \n",
    "\n",
    "    top5=np.argsort(preds,axis=1)[0][::-1]\n",
    "    top5_prob=np.sort(preds,axis=1)[0][::-1]\n",
    "    print(\"=\"*25)\n",
    "    print('Top 5 Predictions')\n",
    "    for i,j in zip(top5[:5],top5_prob[:5]):\n",
    "        print('{0} Yards, Probability {1:.2f}%'.format(i-99,j*100))\n",
    "    print(\"-\"*25)\n",
    "    print('Ground Truth',np.argmax(test)-99,'Yards, Predicted with',round(preds[0][np.argmax(test)]*100,2),'% confidence')\n",
    "    \n",
    "    \n",
    "    end=time.time()\n",
    "    print(\"=\"*25)\n",
    "\n",
    "    print('Time taken to predict a single datapoint',round(end-start),'s')\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d25e9175-7ba7-4d3b-aa0d-d12ad5d00343",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T09:18:52.759070Z",
     "iopub.status.busy": "2022-03-22T09:18:52.758035Z",
     "iopub.status.idle": "2022-03-22T09:19:07.725946Z",
     "shell.execute_reply": "2022-03-22T09:19:07.724964Z",
     "shell.execute_reply.started": "2022-03-22T09:18:52.759070Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to read data: 4 s\n",
      "Time to preprocess full data 7 s\n",
      "=========================\n",
      "Top 5 Predictions\n",
      "3 Yards, Probability 15.25%\n",
      "2 Yards, Probability 15.03%\n",
      "4 Yards, Probability 13.59%\n",
      "1 Yards, Probability 10.66%\n",
      "5 Yards, Probability 8.88%\n",
      "-------------------------\n",
      "Ground Truth 5 Yards, Predicted with 8.88 % confidence\n",
      "=========================\n",
      "Time taken to predict a single datapoint 3 s\n",
      "Wall time: 15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "point_idx=data.sample(1)['PlayId'].values[0]\n",
    "point=data.loc[data.PlayId==point_idx]\n",
    "function_1(point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c47981-7f4d-4655-91c8-1f74c208ccc3",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d63a4ad-d568-4fc4-b29d-34268e2e259d",
   "metadata": {},
   "source": [
    "## Function 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64929293-33d8-4a93-a06d-ff81c2320c34",
   "metadata": {},
   "source": [
    "This function contains the whole dataset and prints the CRPS value of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff72ecc5-cd60-45b2-9dd4-0a1b017e8ebe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T10:51:07.318766Z",
     "iopub.status.busy": "2022-03-22T10:51:07.318766Z",
     "iopub.status.idle": "2022-03-22T10:51:07.359163Z",
     "shell.execute_reply": "2022-03-22T10:51:07.358260Z",
     "shell.execute_reply.started": "2022-03-22T10:51:07.318766Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def function_2(data):\n",
    "    \n",
    "    # preprocess data and prepare data\n",
    "    orient=data.groupby('Position',as_index=False)['Orientation'].mean()\n",
    "    Dir=data.groupby('Position',as_index=False)['Dir'].mean()\n",
    "    OrientDict={}\n",
    "    DirDict={}\n",
    "    for i,j in orient.iterrows():\n",
    "        OrientDict[j['Position']]=j['Orientation']\n",
    "        DirDict[j['Position']]=j['Orientation']\n",
    "\n",
    "    data.Dir=data.Dir.fillna(data.Position.map(DirDict))\n",
    "    data.Orientation=data.Orientation.fillna(data.Position.map(OrientDict))\n",
    "\n",
    "    tempsperweek=data.groupby(['Season','Week'],as_index=False)['Temperature'].mean()\n",
    "    temp2017={}\n",
    "    temp2018={}\n",
    "    temp2019={}\n",
    "    for i,j in tempsperweek.iterrows():\n",
    "        if j['Season']==2017:\n",
    "            temp2017[j['Week']]=j['Temperature']\n",
    "        if j['Season']==2018:\n",
    "            temp2018[j['Week']]=j['Temperature']\n",
    "        if j['Season']==2019:\n",
    "            temp2019[j['Week']]=j['Temperature']\n",
    "\n",
    "    data.loc[(data.Season==2017) & (data.Temperature.isna()),'Temperature']=data.Temperature.fillna(data.Week.map(temp2017))\n",
    "    data.loc[(data.Season==2018) & (data.Temperature.isna()),'Temperature']=data.Temperature.fillna(data.Week.map(temp2018))\n",
    "    data.loc[(data.Season==2019) & (data.Temperature.isna()),'Temperature']=data.Temperature.fillna(data.Week.map(temp2019))\n",
    "\n",
    "    data.loc[data.FieldPosition.isna(),'FieldPosition']='UNKNOWN'\n",
    "    data.loc[data.OffenseFormation.isna(),'OffenseFormation']=data.OffenseFormation.value_counts().idxmax()\n",
    "\n",
    "    data.loc[data.DefendersInTheBox.isna(),'DefendersInTheBox']=data.DefendersInTheBox.median()\n",
    "    data.loc[data.Humidity.isna(),'Humidity']=data.Humidity.median()\n",
    "\n",
    "\n",
    "    #Code to clean StadiumType \n",
    "    #code inspired from https://www.kaggle.com/sanshengshi/lightgbm-clean-stadiumtype\n",
    "    def StadiumType(txt):\n",
    "        txt=str(txt)\n",
    "        txt=txt.lower()\n",
    "        txt=txt.strip()\n",
    "        if 'indoor' in txt or 'closed' in txt:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1   #outdoor or open or unspecified is being treated an as open field \n",
    "    data[\"StadiumType\"]=data[\"StadiumType\"].apply(StadiumType)\n",
    "\n",
    "    def Gameweather(txt):\n",
    "        txt=str(txt)\n",
    "        txt=txt.lower()\n",
    "        txt=txt.strip()\n",
    "        if 'clear' in txt or 'sun' in txt or 'controlled' in txt or 'indoor' in txt:\n",
    "            return 0\n",
    "        if 'rain' in txt:\n",
    "            return 1\n",
    "        if 'cloud' in txt or 'overcast' in txt:\n",
    "            return 0.5 \n",
    "        if 'snow' in txt or 'overcast' in txt:\n",
    "            return -0.5\n",
    "        return 0                                   # Values given to differentiate between clear and rainy \n",
    "    data[\"GameWeather\"]=data[\"GameWeather\"].apply(Gameweather)\n",
    "\n",
    "    def Windspeed(txt):\n",
    "        if pd.isna(txt):\n",
    "            return 7.0                   # Median Value   \n",
    "        if '-' in txt:\n",
    "            a,b=txt.split('-')\n",
    "            return (float(a)+float(b))/2\n",
    "        elif txt.isalnum():\n",
    "            if re.match('(\\d+)',str(txt)):\n",
    "                return float(re.match('(\\d+)',str(txt))[0])\n",
    "            else:\n",
    "                return 7.0\n",
    "        else:\n",
    "            return 0\n",
    "    data[\"WindSpeed\"]=data[\"WindSpeed\"].astype(str)\n",
    "    data[\"WindSpeed\"]=data[\"WindSpeed\"].apply(Windspeed)\n",
    "\n",
    "\n",
    "    # code based from https://www.kaggle.com/bgmello/neural-networks-feature-engineering-for-the-win\n",
    "    def WindDirection(txt):\n",
    "\n",
    "        #Cleaning the values\n",
    "        if pd.isna(txt):\n",
    "            return -1\n",
    "        txt = txt.lower()\n",
    "        txt = ''.join([c for c in txt if c not in punctuation])\n",
    "        txt = txt.replace('from', '')\n",
    "        txt = txt.replace(' ', '')\n",
    "        txt = txt.replace('north', 'n')\n",
    "        txt = txt.replace('south', 's')\n",
    "        txt = txt.replace('west', 'w')\n",
    "        txt = txt.replace('east', 'e')\n",
    "\n",
    "        #assigning the values\n",
    "\n",
    "        deg=360\n",
    "        if txt=='n':\n",
    "            return 0\n",
    "        if txt=='nne' or txt=='nen':\n",
    "            return 1/16*deg\n",
    "        if txt=='ne':\n",
    "            return 2/16*deg\n",
    "        if txt=='ene' or txt=='nee':\n",
    "            return 3/16*deg\n",
    "        if txt=='e':\n",
    "            return 4/16*deg\n",
    "        if txt=='ese' or txt=='see':\n",
    "            return 5/16*deg\n",
    "        if txt=='se':\n",
    "            return 6/16*deg\n",
    "        if txt=='ses' or txt=='sse':\n",
    "            return 7/16*deg\n",
    "        if txt=='s':\n",
    "            return 8/16*deg\n",
    "        if txt=='ssw' or txt=='sws':\n",
    "            return 9/16*deg\n",
    "        if txt=='sw':\n",
    "            return 10/16*deg\n",
    "        if txt=='sww' or txt=='wsw':\n",
    "            return 11/16*deg\n",
    "        if txt=='w':\n",
    "            return 12/16*deg\n",
    "        if txt=='wnw' or txt=='nww':\n",
    "            return 13/16*deg\n",
    "        if txt=='nw':\n",
    "            return 14/16*deg\n",
    "        if txt=='nwn' or txt=='nnw':\n",
    "            return 15/16*deg\n",
    "        return -1\n",
    "                                          # Values given to differentiate between clear and rainy \n",
    "    data[\"WindDirection\"]=data[\"WindDirection\"].apply(WindDirection)\n",
    "    \n",
    "    TeamMap={'ARI':'ARZ','BAL':'BLT','CLE':'CLV','HOU':'HST'}\n",
    "\n",
    "    for k,v in TeamMap.items():\n",
    "        data.loc[data['VisitorTeamAbbr']==k,'VisitorTeamAbbr']=v\n",
    "        data.loc[data['HomeTeamAbbr']==k,'HomeTeamAbbr']=v\n",
    "    data['PlayId']=data['PlayId'].astype(str)\n",
    "    data['PlayerHeight']=data['PlayerHeight'].astype(str)\n",
    "    data['PlayerHeight']=data['PlayerHeight'].str.split('-').apply(lambda x: int(x[0])*0.3048+ int(x[1])*0.0254)\n",
    "    data['PlayerWeight']=data['PlayerWeight']*0.453592\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #first 3 Downs have similar distribution\n",
    "    data['Down']=data.Down.apply(lambda x: 1 if x<3 else 0)\n",
    "    #Standardise Play Direction and dependent features\n",
    "    data['Left']=data.PlayDirection=='left'\n",
    "    \n",
    "    data['X_std']=data.X\n",
    "    data.loc[data.Left,'X_std']=120-data.loc[data.Left,'X']\n",
    "    data['Y_std']=data.Y\n",
    "    data.loc[data.Left,'Y_std']=160/3-data.loc[data.Left,'Y']\n",
    "    \n",
    "    #Rusher varibale to indicate the rushing player\n",
    "    data['Rusher']=data.NflId==data.NflIdRusher\n",
    "    \n",
    "    data['Offense'] = \"home\"\n",
    "    # If attacking team is not home team, it is treated as away team\n",
    "    data.loc[data.PossessionTeam != data.HomeTeamAbbr, 'Offense'] = \"away\"\n",
    "    # If Field position and possession team are same then the Yardline values stay same. Otherwise it is in the opposite direction\n",
    "    data['YardLine_std'] = 100 - data.YardLine\n",
    "    data.loc[data.FieldPosition == data.PossessionTeam,'YardLine_std'] = data.loc[data.FieldPosition == data.PossessionTeam,'YardLine']\n",
    "    \n",
    "    # Degrees to Radians subtracting by 90 since 0 degrees is upwards in raw data and it doesn't make intuitve sense, \n",
    "    # towards right is gven as 0 and towards left as 180 degrees or pi radians\n",
    "    data['Dir_std']=np.mod(90-data.Dir,360)*np.pi/180\n",
    "    #Flipping direction of all Left direction by pi radians (180 degrees)\n",
    "    data.loc[data['Left'],'Dir_std']=np.mod(np.pi-data.loc[data['Left'],'Dir_std'],2*np.pi)\n",
    "    \n",
    "    data.drop(['X','Y','Dir','YardLine'],axis=1,inplace=True)\n",
    "    \n",
    "    #Data Engineering\n",
    "    \n",
    "    #Values taken just from looking at the distrubition of data after comparing 2017 with other Seasons(2018/19)\n",
    "    #Number of samples also taken after looking at the corresponding values in 2018/2019 data respectively \n",
    "    index=data.loc[(data.Season==2017) & (data.Dis==0.0)].sample(2200).index                                          \n",
    "    data.loc[index.values,'Dis']=np.round(np.random.uniform(0.1,0.4,2200),decimals=2)      \n",
    "    index=data.loc[(data.Season==2017) & (data.Dis==0.01)].sample(4000).index\n",
    "    data.loc[index.values,'Dis']=np.round(np.random.uniform(0.1,0.4,4000),decimals=2)\n",
    "    \n",
    "    #201 orientation off byy a phase of 90 degrees\n",
    "    data.loc[data.Season==2017,'Orientation']=np.mod(90+data.loc[data.Season==2017,'Orientation'],360)\n",
    "    \n",
    "    #creating a Play only based Dataframe\n",
    "    df_rush=data.loc[data.Rusher]\n",
    "    \n",
    "    \n",
    "    #Feature engineering for features relative to the Rusher\n",
    "    \n",
    "    #https://www.kaggle.com/jccampos/nfl-2020-winner-solution-the-zoo\n",
    "    # Getting Speed component along vertical and Horizontal Axis\n",
    "    data['S_x'] = data['S']*data['Dir_std'].apply(math.cos)\n",
    "    data['S_y'] = data['S']*data['Dir_std'].apply(math.sin)\n",
    "\n",
    "    #Momentum=mass*velocity along vertical and Horizontal Axis\n",
    "    data['M_x']=data.PlayerWeight*data['S_x']\n",
    "    data['M_y']=data.PlayerWeight*data['S_y']\n",
    "\n",
    "\n",
    "    rush=data[data.Rusher]\n",
    "    rush.set_index('PlayId',inplace=True,drop=True)\n",
    "    #Converting to Dictionary the values of Rusher\n",
    "    mapp=rush[['X_std','Y_std','S_x','S_y','M_x','M_y']].to_dict(orient='index')\n",
    "\n",
    "    #Creating columns which contain the rusher values to all PlayIds\n",
    "    rush_x=data['PlayId'].apply(lambda x:mapp[x]['X_std'])\n",
    "    rush_y=data['PlayId'].apply(lambda y:mapp[y]['Y_std'])\n",
    "    rush_Sx=data['PlayId'].apply(lambda x:mapp[x]['S_x'])\n",
    "    rush_Sy=data['PlayId'].apply(lambda y:mapp[y]['S_y'])\n",
    "    rush_Mx=data['PlayId'].apply(lambda x:mapp[x]['M_x'])\n",
    "    rush_My=data['PlayId'].apply(lambda y:mapp[y]['M_y'])\n",
    "    \n",
    "    #Euclidean Distance between Rusher and other players\n",
    "    data['gap']=((rush_x-data['X_std'])**2+(rush_y-data['Y_std'])**2)**0.5\n",
    "    data['inverse_gap']=data['gap'].apply(lambda x: 1/x if x!=0 else -1)\n",
    "    #Relative Speeds between Rusher and other players\n",
    "    data['RelS_x']=rush_Sx-data['S_x']\n",
    "    data['RelS_y']=rush_Sy-data['S_y']\n",
    "    # Relative Momentum between Rusher and other players\n",
    "    data['RelM_x']=rush_Mx-data['M_x']\n",
    "    data['RelM_y']=rush_My-data['M_y']  \n",
    "\n",
    "\n",
    "    #Code to collapse all 22 players involved per PlayId into a single row arranged from highest to lowest.\n",
    "    playids=data.PlayId.unique()\n",
    "    A=data['gap'].values\n",
    "    B=data['RelS_x'].values\n",
    "    C=data['RelS_y'].values\n",
    "    D=data['inverse_gap'].values\n",
    "    E=data['RelM_x'].values\n",
    "    F=data['RelM_y'].values\n",
    "    n=len(playids)\n",
    "    val_dict={}\n",
    "    for i in range(0,n):\n",
    "        val_dict[playids[i]]=sorted(A[i*22:i*22+22],reverse=True)+sorted(D[i*22:i*22+22])+\\\n",
    "                            sorted(B[i*22:i*22+22],reverse=True)+sorted(C[i*22:i*22+22],reverse=True)+\\\n",
    "                            sorted(E[i*22:i*22+22],reverse=True)+sorted(F[i*22:i*22+22],reverse=True)\n",
    "    val_cols=['P_{0}'.format(i+1) for i in range(0,22)]+['P_Invd_{0}'.format(i+1) for i in range(0,22)]+\\\n",
    "                ['Sx_{0}'.format(i+1) for i in range(0,22)]+['Sy_{0}'.format(i+1) for i in range(0,22)]+\\\n",
    "            ['Mx_{0}'.format(i+1) for i in range(0,22)]+['My_{0}'.format(i+1) for i in range(0,22)]\n",
    "\n",
    "    rel_data=pd.DataFrame(data=val_dict.values(),columns=val_cols,index=list(val_dict.keys()))\n",
    "    rel_data.index.rename('PlayId',inplace=True)\n",
    "    \n",
    "    #Combining Game state and Relative player dataframes\n",
    "    final_df=pd.merge(df_rush,rel_data,on='PlayId')\n",
    "    Y=final_df.Yards.values\n",
    "    \n",
    "    #Dropping redundant or features which don't seem useful \n",
    "    final_df.drop([ 'GameId','S','NflId','Team',\n",
    "           'DisplayName', 'JerseyNumber', 'Season', 'GameClock',\n",
    "           'PossessionTeam', 'FieldPosition',\n",
    "           'HomeScoreBeforePlay', 'VisitorScoreBeforePlay', 'NflIdRusher',\n",
    "           'OffenseFormation', 'OffensePersonnel', 'DefendersInTheBox',\n",
    "           'DefensePersonnel', 'PlayDirection', 'TimeHandoff', 'TimeSnap',\n",
    "           'PlayerHeight', 'PlayerWeight', 'PlayerBirthDate', 'PlayerCollegeName',\n",
    "           'Position', 'HomeTeamAbbr', 'VisitorTeamAbbr', 'Stadium',\n",
    "           'Location', 'StadiumType', 'Turf','Left', 'X_std', 'Y_std',\n",
    "           'Rusher', 'Offense', 'Dir_std','Yards'],inplace=True,axis=1)\n",
    "    \n",
    "    final_df.set_index('PlayId',inplace=True)\n",
    "    Y=np.array(Y).reshape(-1,1)\n",
    "    targets = Y\n",
    "    test=np.zeros((Y.shape[0],199))\n",
    "    \n",
    "    #converting into cdf format\n",
    "    for idx, t in enumerate(list(Y)):\n",
    "        test[idx][99 + t[0]] = 1\n",
    "    \n",
    "    #Loading Model and CRPS function\n",
    "    def crps_nn(y_true,y_pred):\n",
    "        loss = K.mean(K.sum((K.cumsum(y_pred, axis = 1) - K.cumsum(y_true, axis=1))**2, axis=1))/199\n",
    "        return loss\n",
    "    model=load_model('nfl_pred.hdf5',custom_objects={'crps_nn':crps_nn})   \n",
    "    \n",
    "    y_true=np.clip(np.cumsum(test, axis=1), 0, 1)\n",
    "    y_pred=np.clip(np.cumsum(model.predict(final_df), axis=1), 0, 1)\n",
    "    cr=((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * final_df.shape[0])\n",
    "    \n",
    "    print('Continuous Ranked Probability Score:',round(cr,8))\n",
    "    \n",
    "    preds=model.predict(final_df)\n",
    "    return final_df.index,preds,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee3ea067-2e43-42de-9135-12ba4c9a84d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T10:51:07.359163Z",
     "iopub.status.busy": "2022-03-22T10:51:07.359163Z",
     "iopub.status.idle": "2022-03-22T10:51:26.022419Z",
     "shell.execute_reply": "2022-03-22T10:51:26.021422Z",
     "shell.execute_reply.started": "2022-03-22T10:51:07.359163Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous Ranked Probability Score: 0.0134318\n",
      "Wall time: 18.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data=pd.read_csv('train.csv',low_memory=False)\n",
    "p,n,r=function_2(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9288d625-3789-4c3d-9d1a-18cf6c171ba4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T10:51:26.023416Z",
     "iopub.status.busy": "2022-03-22T10:51:26.023416Z",
     "iopub.status.idle": "2022-03-22T10:51:26.050297Z",
     "shell.execute_reply": "2022-03-22T10:51:26.050297Z",
     "shell.execute_reply.started": "2022-03-22T10:51:26.023416Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5717201-3112-4a89-973b-09253c200942",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T10:51:26.050297Z",
     "iopub.status.busy": "2022-03-22T10:51:26.050297Z",
     "iopub.status.idle": "2022-03-22T10:51:26.415862Z",
     "shell.execute_reply": "2022-03-22T10:51:26.414977Z",
     "shell.execute_reply.started": "2022-03-22T10:51:26.050297Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x=np.zeros((31007,3))\n",
    "x[:,0]=p.values\n",
    "for idx,i in enumerate(n):\n",
    "    prob=np.sort(i)[::-1]\n",
    "    a=r[idx,0]-(np.argmax(i)-99)\n",
    "    if a==0:\n",
    "        x[idx,2]=1\n",
    "    else:\n",
    "        x[idx,2]=0\n",
    "    x[idx,1]=prob[0]-prob[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa59fc8b-4c0f-4bba-a9a3-043e94f972b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T10:51:26.417588Z",
     "iopub.status.busy": "2022-03-22T10:51:26.417124Z",
     "iopub.status.idle": "2022-03-22T10:51:26.434981Z",
     "shell.execute_reply": "2022-03-22T10:51:26.434358Z",
     "shell.execute_reply.started": "2022-03-22T10:51:26.417588Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask=x[:,2]==1\n",
    "x=x[mask,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a27084d-a52f-4313-8f28-4dc098808fd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T10:51:26.435342Z",
     "iopub.status.busy": "2022-03-22T10:51:26.435342Z",
     "iopub.status.idle": "2022-03-22T10:51:26.457558Z",
     "shell.execute_reply": "2022-03-22T10:51:26.457558Z",
     "shell.execute_reply.started": "2022-03-22T10:51:26.435342Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "indexes=np.argwhere(x[:,1]>0.05)[:,0]\n",
    "final_index=[int(x[i,0]) for i in indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "131eab28-da32-4255-8fe1-3fef0b05545f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T10:51:26.458843Z",
     "iopub.status.busy": "2022-03-22T10:51:26.458843Z",
     "iopub.status.idle": "2022-03-22T10:51:26.482459Z",
     "shell.execute_reply": "2022-03-22T10:51:26.481484Z",
     "shell.execute_reply.started": "2022-03-22T10:51:26.458843Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "556"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42013f18-e2e9-47f5-a2c0-446e24ce7b5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T10:51:26.482815Z",
     "iopub.status.busy": "2022-03-22T10:51:26.482815Z",
     "iopub.status.idle": "2022-03-22T10:51:30.985177Z",
     "shell.execute_reply": "2022-03-22T10:51:30.985177Z",
     "shell.execute_reply.started": "2022-03-22T10:51:26.482815Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv('train.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03d3bb5e-5ae1-435d-9057-d8dc4b23bf62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T10:51:30.987197Z",
     "iopub.status.busy": "2022-03-22T10:51:30.986693Z",
     "iopub.status.idle": "2022-03-22T10:51:31.067359Z",
     "shell.execute_reply": "2022-03-22T10:51:31.066639Z",
     "shell.execute_reply.started": "2022-03-22T10:51:30.986693Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data=data[data.PlayId.isin(final_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "283d2341-e07f-4a3e-807f-17adb36772cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T10:51:31.067894Z",
     "iopub.status.busy": "2022-03-22T10:51:31.067894Z",
     "iopub.status.idle": "2022-03-22T10:51:31.104373Z",
     "shell.execute_reply": "2022-03-22T10:51:31.103374Z",
     "shell.execute_reply.started": "2022-03-22T10:51:31.067894Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GameId</th>\n",
       "      <th>PlayId</th>\n",
       "      <th>Team</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>S</th>\n",
       "      <th>A</th>\n",
       "      <th>Dis</th>\n",
       "      <th>Orientation</th>\n",
       "      <th>Dir</th>\n",
       "      <th>...</th>\n",
       "      <th>Week</th>\n",
       "      <th>Stadium</th>\n",
       "      <th>Location</th>\n",
       "      <th>StadiumType</th>\n",
       "      <th>Turf</th>\n",
       "      <th>GameWeather</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>WindDirection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>2017090700</td>\n",
       "      <td>20170907001177</td>\n",
       "      <td>away</td>\n",
       "      <td>16.63</td>\n",
       "      <td>18.83</td>\n",
       "      <td>1.94</td>\n",
       "      <td>2.53</td>\n",
       "      <td>0.21</td>\n",
       "      <td>339.25</td>\n",
       "      <td>33.96</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Gillette Stadium</td>\n",
       "      <td>Foxborough, MA</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Field Turf</td>\n",
       "      <td>Clear and warm</td>\n",
       "      <td>63.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>8</td>\n",
       "      <td>SW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>2017090700</td>\n",
       "      <td>20170907001177</td>\n",
       "      <td>away</td>\n",
       "      <td>17.12</td>\n",
       "      <td>22.33</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.17</td>\n",
       "      <td>305.74</td>\n",
       "      <td>350.30</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Gillette Stadium</td>\n",
       "      <td>Foxborough, MA</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Field Turf</td>\n",
       "      <td>Clear and warm</td>\n",
       "      <td>63.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>8</td>\n",
       "      <td>SW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>2017090700</td>\n",
       "      <td>20170907001177</td>\n",
       "      <td>away</td>\n",
       "      <td>17.55</td>\n",
       "      <td>28.83</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.07</td>\n",
       "      <td>35.66</td>\n",
       "      <td>107.79</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Gillette Stadium</td>\n",
       "      <td>Foxborough, MA</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Field Turf</td>\n",
       "      <td>Clear and warm</td>\n",
       "      <td>63.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>8</td>\n",
       "      <td>SW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>2017090700</td>\n",
       "      <td>20170907001177</td>\n",
       "      <td>away</td>\n",
       "      <td>16.48</td>\n",
       "      <td>23.78</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0.31</td>\n",
       "      <td>346.32</td>\n",
       "      <td>67.88</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Gillette Stadium</td>\n",
       "      <td>Foxborough, MA</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Field Turf</td>\n",
       "      <td>Clear and warm</td>\n",
       "      <td>63.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>8</td>\n",
       "      <td>SW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>2017090700</td>\n",
       "      <td>20170907001177</td>\n",
       "      <td>away</td>\n",
       "      <td>14.01</td>\n",
       "      <td>25.76</td>\n",
       "      <td>3.57</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2.95</td>\n",
       "      <td>95.38</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Gillette Stadium</td>\n",
       "      <td>Foxborough, MA</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Field Turf</td>\n",
       "      <td>Clear and warm</td>\n",
       "      <td>63.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>8</td>\n",
       "      <td>SW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682105</th>\n",
       "      <td>2019112500</td>\n",
       "      <td>20191125003496</td>\n",
       "      <td>home</td>\n",
       "      <td>23.34</td>\n",
       "      <td>20.92</td>\n",
       "      <td>1.29</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.14</td>\n",
       "      <td>12.17</td>\n",
       "      <td>28.13</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>Los Angeles Memorial Coliseum</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Clear</td>\n",
       "      <td>62.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>5</td>\n",
       "      <td>WSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682106</th>\n",
       "      <td>2019112500</td>\n",
       "      <td>20191125003496</td>\n",
       "      <td>home</td>\n",
       "      <td>20.63</td>\n",
       "      <td>25.29</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.09</td>\n",
       "      <td>119.81</td>\n",
       "      <td>39.01</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>Los Angeles Memorial Coliseum</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Clear</td>\n",
       "      <td>62.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>5</td>\n",
       "      <td>WSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682107</th>\n",
       "      <td>2019112500</td>\n",
       "      <td>20191125003496</td>\n",
       "      <td>home</td>\n",
       "      <td>21.73</td>\n",
       "      <td>21.18</td>\n",
       "      <td>3.80</td>\n",
       "      <td>2.32</td>\n",
       "      <td>0.37</td>\n",
       "      <td>37.32</td>\n",
       "      <td>354.26</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>Los Angeles Memorial Coliseum</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Clear</td>\n",
       "      <td>62.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>5</td>\n",
       "      <td>WSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682108</th>\n",
       "      <td>2019112500</td>\n",
       "      <td>20191125003496</td>\n",
       "      <td>home</td>\n",
       "      <td>22.32</td>\n",
       "      <td>23.44</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.12</td>\n",
       "      <td>72.71</td>\n",
       "      <td>347.88</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>Los Angeles Memorial Coliseum</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Clear</td>\n",
       "      <td>62.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>5</td>\n",
       "      <td>WSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682109</th>\n",
       "      <td>2019112500</td>\n",
       "      <td>20191125003496</td>\n",
       "      <td>home</td>\n",
       "      <td>17.12</td>\n",
       "      <td>20.89</td>\n",
       "      <td>3.47</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0.34</td>\n",
       "      <td>80.22</td>\n",
       "      <td>59.76</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>Los Angeles Memorial Coliseum</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Clear</td>\n",
       "      <td>62.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>5</td>\n",
       "      <td>WSW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12232 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            GameId          PlayId  Team      X      Y     S     A   Dis  \\\n",
       "308     2017090700  20170907001177  away  16.63  18.83  1.94  2.53  0.21   \n",
       "309     2017090700  20170907001177  away  17.12  22.33  1.06  1.11  0.17   \n",
       "310     2017090700  20170907001177  away  17.55  28.83  0.61  0.08  0.07   \n",
       "311     2017090700  20170907001177  away  16.48  23.78  2.20  1.24  0.31   \n",
       "312     2017090700  20170907001177  away  14.01  25.76  3.57  1.13  0.45   \n",
       "...            ...             ...   ...    ...    ...   ...   ...   ...   \n",
       "682105  2019112500  20191125003496  home  23.34  20.92  1.29  2.31  0.14   \n",
       "682106  2019112500  20191125003496  home  20.63  25.29  0.90  0.82  0.09   \n",
       "682107  2019112500  20191125003496  home  21.73  21.18  3.80  2.32  0.37   \n",
       "682108  2019112500  20191125003496  home  22.32  23.44  1.01  0.89  0.12   \n",
       "682109  2019112500  20191125003496  home  17.12  20.89  3.47  1.92  0.34   \n",
       "\n",
       "        Orientation     Dir  ...  Week                        Stadium  \\\n",
       "308          339.25   33.96  ...     1               Gillette Stadium   \n",
       "309          305.74  350.30  ...     1               Gillette Stadium   \n",
       "310           35.66  107.79  ...     1               Gillette Stadium   \n",
       "311          346.32   67.88  ...     1               Gillette Stadium   \n",
       "312            2.95   95.38  ...     1               Gillette Stadium   \n",
       "...             ...     ...  ...   ...                            ...   \n",
       "682105        12.17   28.13  ...    12  Los Angeles Memorial Coliseum   \n",
       "682106       119.81   39.01  ...    12  Los Angeles Memorial Coliseum   \n",
       "682107        37.32  354.26  ...    12  Los Angeles Memorial Coliseum   \n",
       "682108        72.71  347.88  ...    12  Los Angeles Memorial Coliseum   \n",
       "682109        80.22   59.76  ...    12  Los Angeles Memorial Coliseum   \n",
       "\n",
       "               Location  StadiumType        Turf     GameWeather Temperature  \\\n",
       "308      Foxborough, MA      Outdoor  Field Turf  Clear and warm        63.0   \n",
       "309      Foxborough, MA      Outdoor  Field Turf  Clear and warm        63.0   \n",
       "310      Foxborough, MA      Outdoor  Field Turf  Clear and warm        63.0   \n",
       "311      Foxborough, MA      Outdoor  Field Turf  Clear and warm        63.0   \n",
       "312      Foxborough, MA      Outdoor  Field Turf  Clear and warm        63.0   \n",
       "...                 ...          ...         ...             ...         ...   \n",
       "682105  Los Angeles, CA      Outdoor       Grass           Clear        62.0   \n",
       "682106  Los Angeles, CA      Outdoor       Grass           Clear        62.0   \n",
       "682107  Los Angeles, CA      Outdoor       Grass           Clear        62.0   \n",
       "682108  Los Angeles, CA      Outdoor       Grass           Clear        62.0   \n",
       "682109  Los Angeles, CA      Outdoor       Grass           Clear        62.0   \n",
       "\n",
       "       Humidity  WindSpeed  WindDirection  \n",
       "308        77.0          8             SW  \n",
       "309        77.0          8             SW  \n",
       "310        77.0          8             SW  \n",
       "311        77.0          8             SW  \n",
       "312        77.0          8             SW  \n",
       "...         ...        ...            ...  \n",
       "682105     64.0          5            WSW  \n",
       "682106     64.0          5            WSW  \n",
       "682107     64.0          5            WSW  \n",
       "682108     64.0          5            WSW  \n",
       "682109     64.0          5            WSW  \n",
       "\n",
       "[12232 rows x 49 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96ed5973-5710-4bd0-9b8e-4aa6caf18d3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T10:51:31.106550Z",
     "iopub.status.busy": "2022-03-22T10:51:31.105370Z",
     "iopub.status.idle": "2022-03-22T10:51:31.322495Z",
     "shell.execute_reply": "2022-03-22T10:51:31.322495Z",
     "shell.execute_reply.started": "2022-03-22T10:51:31.106550Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.to_csv('Bestresulting.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71bde68d-abb1-40b7-bed2-b4f94908d747",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T10:51:31.323516Z",
     "iopub.status.busy": "2022-03-22T10:51:31.323516Z",
     "iopub.status.idle": "2022-03-22T10:51:32.225850Z",
     "shell.execute_reply": "2022-03-22T10:51:32.225145Z",
     "shell.execute_reply.started": "2022-03-22T10:51:31.323516Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_df=pd.read_csv('Final_data.csv')\n",
    "final_df=final_df[final_df.PlayId.isin(final_index)]\n",
    "final_df.to_csv('Final_Best_data.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dcc62b-133a-4dbe-a4ae-9d4d2b256f6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
